"""
Run derived collection builder.

See the -h option for details on the options.

Subcommands:

* merge - Merge two collections, e.g., a "sandbox" and core DB.
* list - List builder commands.
* build - Run a builder command.

"""
__author__ = 'Dan Gunter <dkgunter@lbl.gov>'
__date__ = '5/22/13'

# Imports
# -------

# System imports.
import argparse
import ast
import imp
import json
import logging
import os
import sys
import time
import traceback

# Third-party imports.
import pymongo

# Local imports.
from matgendb.builders import core
from matgendb.builders.util import csv_list, csv_dict
from matgendb.query_engine import QueryEngine
from matgendb.builders.incr import TrackedQueryEngine, UnTrackedQueryEngine, Operation

# Global variables.

_log = None     # configured in main()

DEFAULT_CONFIG_FILE = "db.json"

# Suffix for merged tasks collection
MERGED_SUFFIX = "merged"

# Exceptions
# ----------


class BuilderError(Exception):
    pass


class ConfigurationError(BuilderError):
    def __init__(self, where, why):
        Exception.__init__(self, "Failed to load configuration {}: {}".format(where, why))


class BuilderNotFoundError(Exception):
    pass

# Commands
# --------


def command_merge(args):
    """Command: Merge tasks from two collections.
    Intended for merging a sandbox and core db.

    :param args: Command-line arguments
    :type args: list
    """
    # Check args.
    if not args.sandbox_file:
        raise ConfigurationError("sandbox filename",
                                 "In sandbox mode, -s/--sandbox is required")

    # Connect to "core" collections.
    try:
        settings = get_settings(args.config_file)
    except ConfigurationError, err:
        _log.error("command_merge.configuration")
        raise
    core_db = QueryEngine(**settings)
    if hasattr(args, 'merged_tasks') and args.merged_tasks:
        suffix = MERGED_SUFFIX
    else:
        suffix = None
    core_collections = core.Collections(core_db, task_suffix=suffix)

    # Setup.
    sandbox_settings = get_settings(args.sandbox_file)
    sandbox_db = QueryEngine(**sandbox_settings)
    sdb = sandbox_settings['database']
    pfx = args.coll_prefix
    sandbox_collections = core.Collections(sandbox_db, prefix=pfx)
    # set task id prefix
    if args.sandbox_name:
        id_prefix = args.sandbox_name
    elif pfx:
        id_prefix = pfx
    else:
        id_prefix = "sandbox"
    # set target collection name
    if pfx:
        target = "{}.tasks.{}".format(pfx, MERGED_SUFFIX)
    else:
        target = "tasks.{}".format(MERGED_SUFFIX)

    # Perform the merge.
    _log.debug("sandbox.merge.begin: sandbox={}".format(sdb))
    t0 = time.time()
    try:
        core.merge_tasks(core_collections, sandbox_collections, id_prefix, target, wipe=args.wipe_target)
    except pymongo.errors.DuplicateKeyError, err:
        _log.error("sandbox.merge.end error=merge.duplicate_key msg={}".format(err))
        tell_user("\nDuplicate key error from MongoDB.\nUse -W/--wipe to clear target collection before merge.\n")
        return -1
    _log.debug("sandbox.merge.end: sandbox={} duration_sec={:g}".format(sdb, time.time() - t0))
    tell_user("Merged tasks: db={} collection={}".format(sdb, target))

    return 0


def command_list(args):
    """Command: List all the builders in a given module dir.

    :param args: Command-line arguments
    :type args: list
    :return: Number of builders shown
    """
    # Load parent module.
    module = load_module(args.mod_path)
    if module is None:
        print("Error loading module {}. Abort.".format(args.mod_path))
        return 0
    # Get all Python modules in directory.
    path = os.path.dirname(module.__file__)
    pyfiles = [f for f in os.listdir(path) if f.endswith('.py') and not f.startswith('__')]
    # Convert back to full module paths.
    pymods = ["{}.{}".format(args.mod_path, os.path.splitext(f)[0]) for f in pyfiles]
    # Find and show builders in the module paths.
    builders = filter(None, [get_builder(m) for m in pymods])
    n = len(builders)
    if n > 0:
        print("Found {:d} builder{}:".format(n, 's' if n > 1 else ''))
        map(_show_builder, builders)
    else:
        print("No builders found in module {}".format(args.mod_path))
    return n


def _show_builder(b):
    """Print a formatted version of builder info to the console.
    """
    indent = " " * 4
    modname = b.__module__.split(".")[-1]
    print("\n{m}".format(m=modname))
    builder_doc = b.__doc__ or "(no description)"
    print("{i}{desc}".format(i=indent, desc=builder_doc.strip()))
    params = {}
    setup_doc = b.setup.__doc__.split("\n")
    for line in setup_doc:
        s = line.strip()
        if s.startswith(":"):
            words = s.split()
            param_name = words[1].split(":")[0]
            param_desc = ' '.join(words[2:])
            if s.startswith(":param"):
                params[param_name] = [param_desc, None]  # desc goes first
            else:
                params[param_name][1] = param_desc  # type goes second
    print("{i}Parameters:".format(i=indent))
    for key, value in params.iteritems():
        desc, type_ = value
        print("{i}{i}{name} = ({type}) {desc}".format(i=indent, name=key, type=type_, desc=desc))

def command_build(args):
    """Command: Run builder, invoked from 'build' sub-command

    :param args: Command-line arguments
    :type args: list
    """
    # Get builder in module.
    full_mod_path = "{}.{}".format(args.mod_path, args.builder)
    builder_class = get_builder(full_mod_path)
    if builder_class is None:
        raise BuilderNotFoundError("{}".format(full_mod_path))

    # Get keywords from args.
    args_kw = {}
    for kwd in args.keywords:
        try:
            key, value = kwd.split('=', 1)
        except ValueError:
            raise ConfigurationError("for builder '{}'".format(args.builder),
                                     "Bad key=value pair: {}".format(kwd))
        args_kw[key] = value

    # Parse builder's setup() method docstring.
    _log.debug("parse builder docstring")
    params = core.parse_fn_docstring(builder_class.setup)
    qes = list()  # query engines
    for name, info in params.iteritems():
        if not 'type' in info:
            raise ConfigurationError("for builder '{}'".format(args.builder),
                                     "Missing ':type {}: <type>' in docstring".format(name))
        value_type = info['type']
        is_query_engine = is_mqe(value_type)
        try:
            value = args_kw[name]
        except KeyError:
            if is_query_engine:
                value = name  # for collection foo, default to 'foo.json' config
            else:
                if '(optional)' in info['desc']:
                    _log.info("Use default value for parameter '{}'".format(name))
                    continue
                else:
                    raise ConfigurationError("for builder '{}'".format(args.builder),
                                             "Missing value for parameter '{}' in {}".format(name, full_mod_path))
        # take special action for some types
        if is_query_engine:
            qes.append(configure_query_engine(args, args_kw, name, value))
        elif value_type in ('dict', 'list', 'int', 'float'):
            parsed_type = eval(value_type)
            try:
                value = _parse_literal(value, value_type)
                if value is not None and not isinstance(value, parsed_type):
                    raise ValueError()
            except ValueError:
                raise ConfigurationError("parsing key '{}'".format(name),
                                         "value '{}' must be a dictionary like {{'foo':'bar'}}".format(value))
    # Run builder.
    _log.info("run builder, keywords: {}".format(csv_dict(args_kw)))
    builder = builder_class(ncores=args.num_cores)
    count = builder.run(setup_kw=args_kw)
    if count < 1:
        _log.warn("Processed {:d} items".format(count))
    else:
        _log.info("Processed {:d} items".format(count))
    # Save current position, for all query engines
    [qe.set_mark() for qe in qes]
    result = 0

    return result

def _parse_literal(v, vt):
    if not v:
        return None
    return ast.literal_eval(v)

def configure_query_engine(args, args_kw, qe_name, path):
    """Configure a new DB connection.

    :param args: Command-line args
    :param args_kw: Function-specific keywords in args
    :param qe_name: Name of query engine
    :param path: Path to config file
    :return: QueryEngine instance
    :raise: ConfigurationError
    """
    qe = None  # query engine obj
    config_files = [os.path.join(args.config_path, x) for x in [path, path + ".json"]]
    found = False
    for config_file in config_files:
        if os.path.exists(config_file):
            found = True
            break
    if not found:
        tried_paths = csv_list(config_files)
        raise ConfigurationError("while loading DB configuration",
                                 "Configuration file '{}' not found Tried: {}".format(path, tried_paths))
    _log.info("load DB configuration for '{}' from '{}'".format(qe_name, config_file))
    db_settings = get_settings(config_file)
    # pick QE class depending on incremental flag
    if args.incr:
        qe_class = TrackedQueryEngine
        # Update settings to include the type of operation, and field, used
        # to track the position in the source collection.
        try:
            t_op = Operation[args.incr_op]
        except KeyError:
            raise ConfigurationError("while setting incremental operator",
                                     "Unrecognized operation for incremental mode: '{}'".format(args.incr_op))
        db_settings.update(dict(track_operation=t_op, track_field=args.incr_field))
    else:
        qe_class = UnTrackedQueryEngine
    # replace value with MQE obj
    _log.debug("QueryEngine.create settings={}".format(db_settings))
    try:
        args_kw[qe_name] = qe = qe_class(**db_settings)
    except pymongo.errors.ConnectionFailure as err:
        raise BuilderError("Cannot connect from settings in '{}': {}"
                           .format(config_file, err))
    _log.debug("Configured query engine {}: {}".format(qe_name, db_settings))
    return qe


# Utility functions
# -----------------


def tell_user(message):
    """Print something to the user.
    """
    print(message)


def get_settings(config_file, allow_default=True):
    """Read settings from a configuration file.
    """
    try:
        if config_file:
            cfg = json.load(open(config_file))
        elif allow_default and os.path.exists(DEFAULT_CONFIG_FILE):
            cfg = json.load(open(DEFAULT_CONFIG_FILE))
        else:
            raise ValueError("Default configuration '{}' not found".format(DEFAULT_CONFIG_FILE))
    except Exception, err:
        raise ConfigurationError(config_file, err)
    normalize_userpass(cfg)
    normalize_aliases(cfg)
    return cfg


def is_mqe(type_name):
    """Whether this type name is a QueryEngine.
    """
    return type_name.endswith("QueryEngine")


def load_module(module):
    """Extend imp to handle dotted module paths.
    """
    _log.debug("Loading module: {}".format(module))
    parts = module.split('.')
    path, m = None, None
    # navigate packages
    for p in parts[:-1]:
        loc = imp.find_module(p, path)
        m = imp.load_module(p, *loc)
        path = m.__path__
    # load module
    p = parts[-1]
    loc = imp.find_module(p, path)
    try:
        mod = imp.load_module(p, *loc)
    except (ValueError, ImportError) as err:
        _log.warn("Skipping module {} on error: {}".format(module, err))
        mod = None
    return mod


def get_builder(module):
    """Get the (first) Builder subclass found in the module.
    """
    result = None
    moduleobj = load_module(module)
    for name in dir(moduleobj):
        obj = getattr(moduleobj, name)
        #_log.debug("examine {}.{}".format(module, name))
        try:
            if issubclass(obj, core.Builder) and not obj == core.Builder:
                _log.debug("{}.{} is a Builder".format(module, name))
                result = obj
                break
        except TypeError:
            pass
    return result


def normalize_userpass(cfg):
    """In DB conn. config, normalize user/password from readonly and admin prefixes.
    In the end, there will be only keys 'user' and 'password'.
    """
    for pfx in 'readonly', 'admin':  # in reverse order of priority, to overwrite
        if (pfx + '_user') in cfg and (pfx + '_password') in cfg:
            cfg[QueryEngine.USER_KEY] = cfg[pfx + '_user']
            cfg[QueryEngine.PASSWORD_KEY] = cfg[pfx + '_password']
            del cfg[pfx + '_user']
            del cfg[pfx + '_password']


def normalize_aliases(cfg):
    """Normalize the 'aliases_config' used by the QueryEngine class.
    If the user sets something, leave it alone.
    But if there is nothing, use the name of the collection to decide whether
    to let the QueryEngine use its defaults or empty it out.

    :param cfg: Configuration read from JSON
    :type cfg: dict
    :return: None (cfg is modified in-place)
    """
    if QueryEngine.ALIASES_CONFIG_KEY in cfg:
        return  # explicitly set by user, so do nothing
    if cfg[QueryEngine.COLLECTION_KEY] in ('materials', 'tasks'):
        pass  # let the defaults for QueryEngine proceed
    else:
        # explicitly put empty aliases, to override QueryEngine defaults
        cfg[QueryEngine.ALIASES_CONFIG_KEY] = {'aliases': {}, 'defaults': {}}

# Main program
# ------------


def main():
    global _log


    # Configure parent parser for shared args.
    parent_parser = argparse.ArgumentParser(add_help=False)
    parent_parser.add_argument('--quiet', '-q', dest='quiet', action="store_true", default=False,
                               help="Minimal verbosity.")
    parent_parser.add_argument('--verbose', '-v', dest='vb', action="count", default=0,
                               help="Print more verbose messages to standard error. Repeatable. (default=ERROR)")
    # Set up argument parsing.
    p = argparse.ArgumentParser(description="Build databases")
    subparsers = p.add_subparsers(description="Actions")

    # Merge action.
    subp = subparsers.add_parser("merge", help="Merge sandbox and core database",
                                 parents=[parent_parser])
    subp.set_defaults(func=command_merge)
    subp.add_argument("-c", "--config", dest="config_file", type=str, metavar='FILE', default="db.json",
                      help="Configure database connection from FILE (%(default)s)")
    subp.add_argument("-n", "--name", dest="sandbox_name", type=str, metavar="NAME", default=None,
                      help="Sandbox name, for prefixing merged task IDs. "
                           "If not given, try to use -p/--prefix, then default (sandbox)")
    subp.add_argument("-p", "--prefix", dest="coll_prefix", type=str, metavar='PREFIX', default=None,
                      help="Collection name prefix for input (and possibly output) collections")
    subp.add_argument("-s", "--sandbox", dest="sandbox_file", type=str, metavar='FILE', default=None,
                      help="Configure sandbox database from FILE (required)")
    subp.add_argument("-W", "--wipe", dest="wipe_target", action="store_true",
                      help="Wipe target collection, removing all data in it, before merge")

    # List builders action.
    subp = subparsers.add_parser("list", help="list builders",
                                 parents=[parent_parser])
    subp.set_defaults(func=command_list)
    subp.add_argument("-m", "--module", dest="mod_path", type=str, metavar="MODULE",
                      default="matgendb.builders",
                      help="Find builder modules under MODULE (default=matgendb.builders)")

    # Build action.
    subp = subparsers.add_parser("build", help="run a builder",
                                 parents=[parent_parser])
    subp.set_defaults(func=command_build)
    subp.add_argument("-b", "--builder", dest="builder", type=str, metavar="NAME", default="",
                      help="Run builder NAME, which is relative to the module path in -m/--module")
    subp.add_argument("-i", "--incr", dest="incr", action="store_true", default=False,
                      help="Incremental mode, only build from new values in source. See also: --incr-op and --incr-field.")
    incr_ops_nocopy = csv_list(set(Operation.__members__.keys()) - set([Operation.copy.name]))
    subp.add_argument("--incr-op", dest="incr_op", type=str, default=Operation.copy.name,
                      help="Operation name for incremental mode: *%(default)s, {}".format(incr_ops_nocopy))
    subp.add_argument("--incr-field", dest="incr_field", type=str, default="_id",
                      help="Field to sort on for incremental mode (%(default)s)")
    subp.add_argument("-C", "--config-path", dest="config_path", type=str, metavar='DIR', default=".",
                      help="Configure database connection from .json files in DIR (default=%(default)s)")
    subp.add_argument("-k", "--kvp", dest="keywords", action="append", default=[],
                      help="Key/value pairs, in format <key>=<value>, passed to builder function. "
                           "For QueryEngine arguments, the value should be the name of a DB configuration file, "
                           "relative to the path given by -C/--config-path, without the '.json' suffix; if not given, "
                           "a configuration file '<key>.json' will be assumed.")
    subp.add_argument("-m", "--module", dest="mod_path", type=str, metavar="MODULE",
                      default="matgendb.builders",
                      help="Find builder modules under MODULE (default=matgendb.builders)")
    subp.add_argument("-n", "--ncores", dest="num_cores", type=int, default=16,
                      help="Number of cores or processes to run in parallel (%(default)d)")
    subp.add_argument("-p", "--prefix", dest="coll_prefix", type=str, metavar='PREFIX', default=None,
                      help="Collection name prefix for input (and possibly output) collections")
    # Parse arguments.
    args = p.parse_args()

    # Configure logging.
    _log = logging.getLogger("mg")  # parent
    _log.propagate = False
    hndlr = logging.StreamHandler()
    hndlr.setFormatter(logging.Formatter("[%(levelname)-6s] %(asctime)s %(name)s :: %(message)s"))
    _log.addHandler(hndlr)
    if args.quiet:
        lvl = logging.CRITICAL
    else:
        if args.vb > 1:
            lvl = logging.DEBUG
        elif args.vb > 0:
            lvl = logging.INFO
        else:
            lvl = logging.WARN
    _log.setLevel(lvl)
    _log = logging.getLogger("mg.build")
    # don't send logs up

    # Run function.
    if args.func is None:
        p.error("No action given")
    try:
        result = args.func(args)
    except ConfigurationError as err:
        _log.error("Configuration error: {}".format(err))
        result = -1
    except BuilderNotFoundError as err:
        _log.error("Builder not found: {}".format(err))
        result = -1
    except BuilderError as err:
        _log.error("{}".format(err))
        result = -1
    except Exception as err:
        if _log.getEffectiveLevel() <= logging.INFO:
            print("{}".format(traceback.format_exc()))
        p.error("{} error: {}".format(args.func.__name__, err))
        result = -2
    if result < 0:
        _log.error("Failure: {:d}".format(result))
    return result

if __name__ == '__main__':
    sys.exit(main())
